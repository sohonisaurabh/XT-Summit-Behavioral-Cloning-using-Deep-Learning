{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"recorded-data\"\n",
    "steering_offset = 0.25\n",
    "model_name = \"xt-summit-model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lines(path):\n",
    "    lines = []\n",
    "    with open(path + \"/driving_log.csv\") as datafile:\n",
    "        reader = csv.reader(datafile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "def extract_images(line):\n",
    "    #print(data_path + \"/IMG/\" + line[0].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    center_image = cv2.imread(data_path + \"/IMG/\" + line[0].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    left_image = cv2.imread(data_path + \"/IMG/\" + line[1].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    right_image = cv2.imread(data_path + \"/IMG/\" + line[2].replace(\"\\\\\", \"/\").split(\"/\")[-1])\n",
    "    return (center_image, left_image, right_image)\n",
    "\n",
    "def extract_steering_angles(line):\n",
    "    steering_angle_center = float(line[3])\n",
    "    steering_angle_left = steering_angle_center + steering_offset\n",
    "    steering_angle_right = steering_angle_center - steering_offset\n",
    "    return (steering_angle_center, steering_angle_left, steering_angle_right)\n",
    "\n",
    "def get_data_without_generator(path, lines):\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for line in lines:\n",
    "        center_image, left_image, right_image = extract_images(line)\n",
    "        center_image, left_image,right_image = convert_to_yuv(center_image), convert_to_yuv(left_image), convert_to_yuv(right_image)\n",
    "        center_image, left_image,right_image = resize(center_image, (0.5, 0.5)), resize(left_image,(0.5, 0.5)), resize(right_image, (0.5, 0.5))\n",
    "        center_image, left_image,right_image = crop_image(center_image), crop_image(left_image), crop_image(right_image)\n",
    "        steering_angle_center, steering_angle_left, steering_angle_right = extract_steering_angles(line)\n",
    "        images.extend([center_image, left_image, right_image])\n",
    "        steering_angles.extend([steering_angle_center, steering_angle_left, steering_angle_right])\n",
    "    return np.array(images), np.array(steering_angles)\n",
    "\n",
    "def convert_to_yuv(image):\n",
    "    converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    return converted_image\n",
    "\n",
    "def crop_image(image):\n",
    "    mask = np.ones_like(image)\n",
    "    xsize, ysize = image.shape[1], image.shape[0]\n",
    "    vertices = ((0, 0.4375*ysize), (0, ysize), (xsize, ysize), (xsize, 0.4375*ysize))\n",
    "    vertexArr = []\n",
    "    for vertex in vertices:\n",
    "        vertexArr.append((vertex[0], vertex[1]))\n",
    "    vertexArr = np.array([vertexArr], dtype=np.int32)\n",
    "    \n",
    "    cv2.fillPoly(mask, vertexArr, (255, 255, 255))\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image\n",
    "\n",
    "def resize(image, scale_factor, size=(200, 66)):\n",
    "    #resized_image = cv2.resize(image, (0,0), fx=scale_factor[0], fy=scale_factor[1]) \n",
    "    resized_image = cv2.resize(image, size) \n",
    "    return resized_image\n",
    "\n",
    "def flip_vertical(image):\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    return flipped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, channel_in, channel_out, layer_name=\"convLayer\", weight_name=\"W\", bias_name=\"B\", \n",
    "               conv_kernel_size=5, use_pool=True):\n",
    "    with tf.name_scope(layer_name):\n",
    "        w = tf.Variable(tf.zeros([conv_kernel_size, conv_kernel_size, channel_in, channel_out]), name=weight_name)\n",
    "        b = tf.Variable(tf.zeros(channel_out), name=bias_name)\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "        conv = tf.nn.bias_add(conv, b)\n",
    "        conv = tf.nn.relu(conv)\n",
    "        if (use_pool):\n",
    "            pool = tf.nn.avg_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "        else:\n",
    "            pool = conv\n",
    "        tf.summary.histogram(\"Weights\", w)\n",
    "        tf.summary.histogram(\"Biases\", b)\n",
    "        tf.summary.histogram(\"Activation\", conv)\n",
    "        return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def full_layer(input, channel_in, channel_out, layer_name=\"fullLayer\", weight_name=\"W\", bias_name=\"B\"):\n",
    "    with tf.name_scope(layer_name):\n",
    "        w = tf.Variable(tf.zeros([channel_in, channel_out]), name=weight_name)\n",
    "        b = tf.Variable(tf.zeros(channel_out), name=bias_name)\n",
    "        full = tf.add(tf.matmul(input, w), b)\n",
    "        full = tf.nn.relu(full)\n",
    "        tf.summary.histogram(\"Weights\", w)\n",
    "        tf.summary.histogram(\"Biases\", b)\n",
    "        tf.summary.histogram(\"Activation\", full)\n",
    "        return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_of_epochs = 5\n",
    "dropout_keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "def run_network_arch (x):\n",
    "    \n",
    "    conv1 = conv_layer(x, 3, 24, layer_name=\"convLayer1\", weight_name=\"weightConv1\", bias_name=\"biasConv1\")\n",
    "    \n",
    "    conv2 = conv_layer(conv1, 24, 36, layer_name=\"convLayer2\", weight_name=\"weightConv2\", bias_name=\"biasConv2\")\n",
    "    \n",
    "    conv3 = conv_layer(conv2, 36, 48, layer_name=\"convLayer3\", weight_name=\"weightConv3\", bias_name=\"biasConv3\")\n",
    "    \n",
    "    conv4 = conv_layer(conv3, 48, 64, layer_name=\"convLayer4\", weight_name=\"weightConv4\", bias_name=\"biasConv4\", \n",
    "                       conv_kernel_size=3)\n",
    "    \n",
    "    flat = flatten(conv4)\n",
    "    \n",
    "    fc1 = full_layer(flat, 576, 100, layer_name=\"fullLayer1\", weight_name=\"weightFull1\", bias_name=\"biasFull1\")\n",
    "    \n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob=dropout_keep_prob)\n",
    "    \n",
    "    fc2 = full_layer(fc1, 100, 50, layer_name=\"fullLayer2\", weight_name=\"weightFull2\", bias_name=\"biasFull2\")\n",
    "    \n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob=dropout_keep_prob)\n",
    "      \n",
    "    logits = full_layer(fc2, 50, 1, layer_name=\"fullLayer3\", weight_name=\"weightFull3\", bias_name=\"biasFull3\")\n",
    "    \n",
    "    #tf.summary.image(\"Logit\", fc2, 50)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import xavier_initializer\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, (None, 66, 200, 3), name=\"InputImages\")\n",
    "tf.summary.image(\"Input\", x, 3)\n",
    "y = tf.placeholder(tf.float32, (None), name=\"OutputSteeringAngle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = run_network_arch(x)\n",
    "with tf.name_scope(\"Entropy\"):\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits, y)\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar(\"Loss\", loss_operation)\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalute performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy_operation)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset + batch_size], y_data[offset:offset + batch_size]\n",
    "        batch_y = np.array(batch_y, dtype=np.float64).reshape(len(batch_y), 1)\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    lines = load_lines(data_path)[1:]\n",
    "    training_set_lines, validation_set_lines = train_test_split(lines, test_size=0.2)\n",
    "    \n",
    "    nb_training = len(training_set_lines)*6\n",
    "    nb_validation = len(validation_set_lines)*6\n",
    "\n",
    "    training_images, steering_angles = get_data_without_generator(data_path, lines[0:500])\n",
    "    return (training_images, steering_angles)\n",
    "data_path = \"data-from-udacity\"\n",
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Train in TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 is complete!\n",
      "Validation loss for Epoch 0 is:  0.693147\n",
      "Epoch  1 is complete!\n",
      "Validation loss for Epoch 1 is:  0.693147\n",
      "Epoch  2 is complete!\n",
      "Validation loss for Epoch 2 is:  0.693147\n",
      "Epoch  3 is complete!\n",
      "Validation loss for Epoch 3 is:  0.693147\n",
      "Epoch  4 is complete!\n",
      "Validation loss for Epoch 4 is:  0.693147\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "saver = tf.train.Saver()\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"tensorboard-graphs/tensorboard/2\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_of_epochs):\n",
    "        images, angles = main()\n",
    "        training_images, valid_images, steering_angles, valid_steering_angles = train_test_split(images, angles)\n",
    "        training_images, steering_angles = shuffle(training_images, steering_angles)\n",
    "        for offset in range(0, len(training_images), batch_size):\n",
    "            current_input_batch = training_images[offset: offset + batch_size]\n",
    "            current_labels_batch = steering_angles[offset: offset + batch_size]\n",
    "            current_labels_batch = np.array(current_labels_batch, dtype=np.float64).reshape(len(current_labels_batch), 1)\n",
    "            sess.run(training_operation, feed_dict={x: current_input_batch, y: current_labels_batch})\n",
    "            s = sess.run(merged_summary, feed_dict={x: current_input_batch, y: current_labels_batch})\n",
    "            writer.add_summary(s, i)\n",
    "        training_accuracy = evaluate(training_images, steering_angles)\n",
    "        valid_steering_angles = np.array(valid_steering_angles).reshape(len(valid_steering_angles), 1)\n",
    "        training_loss = sess.run(loss_operation, feed_dict={x: valid_images, y: valid_steering_angles})\n",
    "        \n",
    "        print(\"Epoch \", i, \"is complete!\")\n",
    "        print(\"Validation loss for Epoch \" +  str(i) + \" is: \", training_loss)\n",
    "    saver.save(sess, './xt-summit.ckpt')\n",
    "    writer.add_graph(sess.graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
